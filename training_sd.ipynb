{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "YrLAHZiW_utf"
      },
      "source": [
        "修改DIR跟model_save_location變數，把檔案放進DIR\n",
        "\n",
        "wav跟txt放在同一個目錄(DIR)\n",
        "\n",
        "檔名要一樣，副檔名.wav and .txt\n",
        "\n",
        "可直接全部執行"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "ubxjWxiH_YS-"
      },
      "outputs": [],
      "source": [
        "DIR = 'snare_drum'\n",
        "LABELS = ['no', 'yes'] # Has onset: no = 0, yes = 1\n",
        "NUM_CLASSES = len(LABELS)\n",
        "PLOT_SAVE_LOCATION = '.'\n",
        "model_save_location = './model_sd'\n",
        "\n",
        "CHANNELS = [2048]  # [1024, 2048, 4096]\n",
        "MEL_BANDS = 80\n",
        "TIME_FRAMES = 12\n",
        "DIFF_FROM_ONSET_MS = 0.03\n",
        "THRESHOLD_FREQ = 15000\n",
        "\n",
        "BATCHES = [64]#, 256, 512]\n",
        "EPOCHS = 50\n",
        "PATIENCE = 150\n",
        "TRAIN_TEST_SPLIT = 0.10\n",
        "TRAIN_VAL_SPLIT = 0.20\n",
        "\n",
        "# Categorical cross-entropy expects labels to be provided in a one-hot representation (0, 1).\n",
        "LOSS_FUNCTION = 'categorical_crossentropy'\n",
        "LEARNING_RATE = 0.001\n",
        "\n",
        "INPUT_SHAPE = (MEL_BANDS, TIME_FRAMES, len(CHANNELS))\n",
        "PRED_LAYER_ACTIVATION = 'sigmoid'\n",
        "METRICS = ['acc']\n",
        "PREC_REC_FSCORE_AVERAGE = 'macro'  # None # 'weighted' # 'micro'\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "OwKUKXKy_iAs"
      },
      "source": [
        "# Some functions for processing data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "8DA3DxrWo_Gp"
      },
      "outputs": [],
      "source": [
        "from processing import SpectrogramProcessor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "sx_i52UiA_Js"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import os.path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "from pathlib import Path\n",
        "\n",
        "import librosa\n",
        "import librosa.display\n",
        "from pydub import AudioSegment\n",
        "from scipy.io import wavfile\n",
        "from scipy.signal import stft, spectrogram\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "\n",
        "class DatasetGenerator:\n",
        "    def __init__(self, \n",
        "                 label_set, \n",
        "                 sample_rate=44100,\n",
        "                 channels=[2048],\n",
        "                 mel_bands=80,\n",
        "                 time_frames=15,\n",
        "                 diff_from_onset_ms=0.030,\n",
        "                 threshold_freq=15500):\n",
        "        \n",
        "        self.label_set = label_set\n",
        "        self.sample_rate = sample_rate\n",
        "        self.channels = channels\n",
        "        self.mel_bands = mel_bands\n",
        "        self.time_frames = time_frames\n",
        "        self.diff_from_onset_ms = diff_from_onset_ms\n",
        "        self.threshold_freq = threshold_freq    \n",
        "\n",
        "    def construct_wav_annotation_pair_data_frame(self, directory):\n",
        "      files = list(Path(dir).rglob('*wav'))\n",
        "      wav_annotation_pairs = []\n",
        "\n",
        "      for file in files:\n",
        "        wav_file_path = os.path.join(dir, file.name)\n",
        "        filename_base = Path(wav_file_path).stem\n",
        "        annotation_file_path = os.path.join(directory, filename_base + '.txt')\n",
        "\n",
        "        if os.path.isfile(annotation_file_path):\n",
        "                wav_annotation_pair = (wav_file_path, annotation_file_path)\n",
        "                wav_annotation_pairs.append(wav_annotation_pair)\n",
        "      data_frame = pd.DataFrame(wav_annotation_pairs, columns=['wave_file', 'annotation'])\n",
        "      self.data_frame = data_frame\n",
        "\n",
        "      return data_frame\n",
        "\n",
        "\n",
        "    def read_wav_file(self, x):\n",
        "        # Read wavfile using scipy wavfile.read.\n",
        "        _, wav = wavfile.read(x) \n",
        "        \n",
        "        # Normalize.\n",
        "        wav = wav.astype(np.float32) / np.iinfo(np.int16).max\n",
        "        \n",
        "        wav_dim = np.shape(wav)\n",
        "        if len(wav_dim) == 2:\n",
        "            # Convert stereo to mono.\n",
        "            wav = wav.sum(axis=1) / 2\n",
        "        \n",
        "        return wav\n",
        "\n",
        "\n",
        "    def process_wav_file(self, wav_file, annotation_file, win_length=2048, eps=1e-10):\n",
        "      wav = self.read_wav_file(wav_file)\n",
        "      sample_rate = self.sample_rate\n",
        "      hop_length = 441 # win_length // 4 # 2048 // 4 = 512\n",
        "      noverlap = win_length - hop_length#***********************************************************************************************\n",
        "      \n",
        "      freqs, times, spec = spectrogram(wav, sample_rate, window='hann', nperseg=win_length, noverlap=noverlap, mode='complex')\n",
        "      _, S_percussive = librosa.decompose.hpss(spec, margin=(1.0, 5.0))\n",
        "      S = librosa.feature.melspectrogram(S=np.abs(S_percussive), sr=sample_rate, window='hann', win_length=win_length, hop_length=hop_length, n_mels=self.mel_bands, center=False, fmax=self.threshold_freq)\n",
        "      S_db = librosa.core.power_to_db(S, ref=np.max)\n",
        "      S_expanded = np.expand_dims(S_db, axis=2)\n",
        "\n",
        "      spectrograms = []\n",
        "      sp = SpectrogramProcessor(S_expanded, times, annotation_file)\n",
        "      spectrograms = sp.split_spectrogram(self.time_frames)\n",
        "      annotations = sp.get_annotations()\n",
        "      onsets = sp.get_onsets(spectrograms, annotations, self.diff_from_onset_ms)\n",
        "      spectrograms = [s[0] for s in spectrograms]  # Remove time indices.\n",
        "\n",
        "      return spectrograms, onsets\n",
        "\n",
        "    \n",
        "    def split_train_test_set(self, test_size, random_state):\n",
        "      self.df_train, self.df_test = train_test_split(\n",
        "                  self.df, \n",
        "                  test_size=test_size, \n",
        "                  random_state=random_state)\n",
        "      \n",
        "\n",
        "    def apply_train_test_split_by_windows(self, test_size, shuffle_train_data=True):\n",
        "        self.df_train = self.df\n",
        "        data, labels = self.get_train_test_validation_data('train', shuffle_train_data=shuffle_train_data)\n",
        "        \n",
        "        larger_portion = int(len(data)*(1-test_size))\n",
        "        train_data = data[:larger_portion]\n",
        "        train_labels = labels[:larger_portion]\n",
        "        test_data = data[larger_portion:]\n",
        "        test_labels = labels[larger_portion:]\n",
        "\n",
        "        # Remove effects of to_categorical function, convert to binary.\n",
        "        test_labels = np.argmax(test_labels, axis=1)\n",
        "        return train_data, train_labels, test_data, test_labels  \n",
        "\n",
        "\n",
        "    def load_wav_and_annotation_files(self, dir):\n",
        "        files = list(Path(dir).rglob('*wav'))\n",
        "        data = []\n",
        "\n",
        "        # Loop over files to get samples.\n",
        "        for file in files:\n",
        "            wav_file = os.path.join(dir, file.name)\n",
        "            filename_base = Path(wav_file).stem\n",
        "            # Files with '_acc' contain only the accompaniment track.\n",
        "            if '_acc' in filename_base:\n",
        "                continue\n",
        "            else:\n",
        "                # NOTE: Modify the annotation file format and paths to suit your\n",
        "                # needs.\n",
        "                annotations_path = os.path.join(dir, filename_base + '.txt')\n",
        "            # If wav file has matching drum instrument annotation file, add to input data.\n",
        "            if os.path.isfile(annotations_path):\n",
        "                sample = (wav_file, annotations_path)\n",
        "                data.append(sample)\n",
        "\n",
        "        # Data Frames with wavs and matching annotation paths.\n",
        "        df = pd.DataFrame(data, columns=['wav_file', 'annotations'])\n",
        "        self.df = df\n",
        "        return df\n",
        "\n",
        "#-------\n",
        "    def get_train_test_validation_data(self, mode, shuffle_train_data=True):\n",
        "        if mode == 'train':\n",
        "            df = self.df_train\n",
        "            # Shuffle input data.\n",
        "            audiofile_ids = random.sample(range(df.shape[0]), df.shape[0]) if shuffle_train_data else list(range(df.shape[0])) \n",
        "        elif mode == 'val':\n",
        "            df = self.df_val\n",
        "            audiofile_ids = list(range(df.shape[0]))\n",
        "        elif mode == 'test':\n",
        "            df = self.df_test\n",
        "            audiofile_ids = list(range(df.shape[0]))\n",
        "        else:\n",
        "            raise ValueError('The mode should be either train, val or test.')        \n",
        "        return self.get_singlechannel_data(df, audiofile_ids, mode == 'test')\n",
        "\n",
        "#---------\n",
        "    def get_singlechannel_data(self, df, audiofile_ids, is_test):\n",
        "        input_data = []\n",
        "        labels = []\n",
        "\n",
        "        for i in range(0, len(audiofile_ids)):\n",
        "            for win_length in self.channels:\n",
        "                spectrograms, onsets = self.process_wav_file(df.wav_file.values[i], df.annotations.values[i], win_length=win_length)\n",
        "                input_data.extend(spectrograms)\n",
        "                labels.extend(onsets)\n",
        "        \n",
        "        # Convert to numpy array.\n",
        "        input_data = np.array(input_data)\n",
        "\n",
        "        if not is_test:\n",
        "            # Process labels to one-hot encoding.\n",
        "            labels = to_categorical(labels, num_classes=len(self.label_set))\n",
        "\n",
        "        return input_data, labels"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "kT3LfbJGCald"
      },
      "source": [
        "# CNN model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "rIOGCM4xCZjN"
      },
      "outputs": [],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import InputLayer\n",
        "\n",
        "def deep_cnn_sequential(features_shape, num_classes, act='relu'):\n",
        "    \"\"\" CNN model for a single drum instrument training.\n",
        "    May use the same model for e.g. snare, bass drum and hi-hat onset training.\n",
        "    \"\"\"\n",
        "    model = keras.Sequential()\n",
        "\n",
        "    model.add(InputLayer(name='inputs', input_shape=features_shape, dtype='float32'))\n",
        "    # Block 1\n",
        "    model.add(tf.keras.layers.Conv2D(10, (3, 7), activation='relu', padding='same', strides=1, name='block1_conv', input_shape=features_shape))\n",
        "    model.add(tf.keras.layers.MaxPooling2D((3, 1), strides=(2,2), padding='same', name='block1_pool'))\n",
        "    model.add(tf.keras.layers.BatchNormalization(name='block1_norm'))\n",
        "    \n",
        "    # Block 2\n",
        "    model.add(tf.keras.layers.Conv2D(20, (3, 3), activation='relu', padding='same', strides=1, name='block2_conv'))\n",
        "    model.add(tf.keras.layers.MaxPooling2D((3, 1), strides=(2,2), padding='same', name='block2_pool'))\n",
        "    model.add(tf.keras.layers.BatchNormalization(name='block2_norm'))\n",
        "\n",
        "    # Flatten\n",
        "    model.add(tf.keras.layers.Flatten(name='flatten'))\n",
        "    \n",
        "    # Fully connected layer 1\n",
        "    model.add(tf.keras.layers.Dense(256, activation='relu', name='dense'))\n",
        "    model.add(tf.keras.layers.BatchNormalization(name='dense_norm'))\n",
        "    model.add(tf.keras.layers.Dropout(0.5, name='dropout'))\n",
        "    \n",
        "    # Prediction (Fully connected layer 2)\n",
        "    # 2 predictions: onset or no onset\n",
        "    model.add(tf.keras.layers.Dense(num_classes, activation=act, name='pred'))\n",
        "\n",
        "    # Print network summary\n",
        "    model.summary()\n",
        "\n",
        "    return model"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "U21-meInCgH-"
      },
      "source": [
        "# Some functions for training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdSGSU1a-DCj",
        "outputId": "0373de76-fc24-4fc4-8c9d-f74ebe564a8a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_54348/2078683331.py:56: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
            "  _, wav = wavfile.read(x)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training data size:  118910\n",
            "Test data size:  13213\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "\n",
        "import matplotlib\n",
        "from matplotlib import pyplot as plt\n",
        "# Disable showing figures to prevent random GPU failures.\n",
        "matplotlib.use('Agg')\n",
        "\n",
        "import os\n",
        "import random as python_random\n",
        "import codecs\n",
        "\n",
        "#from sklearn.metrics import accuracy_score, confusion_matrix, precision_recall_fscore_support, precision_recall_curve, plot_precision_recall_curve\n",
        "from sklearn.utils import class_weight\n",
        "\n",
        "import tensorflow as tf\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "def prepare_data(directory):\n",
        "    # Set to global scope for easy access in other functions.\n",
        "    global TRAIN_DATA\n",
        "    global TRAIN_LABELS\n",
        "    global TRAIN_LABELS_1D\n",
        "    global TEST_DATA\n",
        "    global TEST_LABELS\n",
        "\n",
        "    dsGen = DatasetGenerator(label_set=LABELS,\n",
        "                             sample_rate=44100,\n",
        "                             channels=CHANNELS,\n",
        "                             mel_bands=MEL_BANDS,\n",
        "                             time_frames=TIME_FRAMES,\n",
        "                             diff_from_onset_ms=DIFF_FROM_ONSET_MS,\n",
        "                             threshold_freq=THRESHOLD_FREQ)\n",
        "    \n",
        "    dsGen.load_wav_and_annotation_files(directory)\n",
        "    TRAIN_DATA, TRAIN_LABELS, TEST_DATA, TEST_LABELS = dsGen.apply_train_test_split_by_windows(test_size=TRAIN_TEST_SPLIT, shuffle_train_data=True)\n",
        "\n",
        "    print('Training data size: ', len(TRAIN_DATA))\n",
        "    print('Test data size: ', len(TEST_DATA))\n",
        "\n",
        "\n",
        "prepare_data(DIR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "ja5EFUI9CDcD"
      },
      "outputs": [],
      "source": [
        "def plot(metric1, metric2, label1, label2, save_location, id, batch_size):\n",
        "    \"\"\"\n",
        "    Creates and saves the plotted figure.\n",
        "    \"\"\"\n",
        "    try: \n",
        "        fig = plt.figure()\n",
        "        plt.plot(metric1, label=label1)\n",
        "        plt.plot(metric2, label=label2, linestyle='dashed')\n",
        "        plt.legend()\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.grid(linestyle='dotted')\n",
        "        # plt.ylim(top=)\n",
        "        # plt.show()\n",
        "        plt.savefig(save_location + id + '_' + DRUM_INSTRUMENT + '_' + str(EPOCHS) + '_' + str(batch_size) + '.pdf')\n",
        "        plt.clf()\n",
        "        plt.cla()\n",
        "        plt.close(fig=fig)\n",
        "    except Exception as e:\n",
        "        print('Failed to create plot: ', e)\n",
        "\n",
        "\n",
        "def get_model():\n",
        "    \"\"\"\n",
        "    Build and compile a CNN model. \n",
        "    \"\"\"\n",
        "    # Reset scheduled learning rate.\n",
        "    #learning_rate_schedule = CustomScheduleTanh(warmup_steps=3000, phase_step=25000, max_lr=LEARNING_RATE)\n",
        "    learning_rate_schedule=0.001\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate_schedule, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
        "    \n",
        "    model = deep_cnn_sequential(INPUT_SHAPE, NUM_CLASSES, act=PRED_LAYER_ACTIVATION)\n",
        "    model.compile(optimizer=optimizer, loss=LOSS_FUNCTION, metrics=METRICS)\n",
        "    return model\n",
        "\n",
        "\n",
        "def train(model, batch_size):\n",
        "    \"\"\"\n",
        "    Train the model and return history results.\n",
        "    \"\"\"\n",
        "    global TRAIN_LABELS_1D\n",
        "    global TRAIN_DATA\n",
        "    global TRAIN_LABELS\n",
        "\n",
        "    callbacks = [EarlyStopping(monitor='val_loss', min_delta=0.01, patience=PATIENCE, verbose=1, mode='auto')]\n",
        "    # Balance imbalanced onset classes.\n",
        "    #class_weights = class_weight.compute_class_weight('balanced', np.unique(TRAIN_LABELS_1D), TRAIN_LABELS_1D)\n",
        "\n",
        "    history = model.fit(x=TRAIN_DATA, \n",
        "                        y=TRAIN_LABELS, \n",
        "                        batch_size=batch_size,\n",
        "                        epochs=EPOCHS,\n",
        "                        verbose=1,\n",
        "                        callbacks=callbacks,\n",
        "                        validation_split=TRAIN_VAL_SPLIT)\n",
        "    return history\n",
        "\n",
        "\n",
        "def predict(model):\n",
        "    global TEST_DATA\n",
        "    global TEST_LABELS\n",
        "\n",
        "    y_true = TEST_LABELS\n",
        "    #y_pred = model.predict_classes(x=TEST_DATA, verbose=1)\n",
        "    y_pred = model.predict(TEST_DATA, verbose=1) \n",
        "    y_pred = np.argmax(y_pred, axis=1)\n",
        "\n",
        "    return y_true, y_pred\n",
        "\n",
        "\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, precision_recall_fscore_support, precision_recall_curve\n",
        "def get_metrics(y_true, y_pred):\n",
        "    acc_score = accuracy_score(y_true, y_pred)\n",
        "    precision, recall, fscore, _ = precision_recall_fscore_support(y_true, y_pred, average=PREC_REC_FSCORE_AVERAGE)\n",
        "    return precision, recall, fscore, acc_score\n",
        "\n",
        "\n",
        "def get_confusion_matrix(y_true, y_pred):\n",
        "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
        "    return tn, fp, fn, tp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "rJ4IdbNcCEvM"
      },
      "outputs": [],
      "source": [
        "def run(batch_size):\n",
        "  global model_save_location\n",
        "  \n",
        "  start = time.time()\n",
        "  model = get_model()\n",
        "  history = train(model, batch_size)\n",
        "\n",
        "  model.save(model_save_location)\n",
        "\n",
        "  y_true, y_pred = predict(model)\n",
        "  precision, recall, fscore, acc_score = get_metrics(y_true, y_pred)\n",
        "  '''\n",
        "  tn, fp, fn, tp = get_confusion_matrix(y_true, y_pred)\n",
        "  '''\n",
        "  acc = history.history['acc']\n",
        "  val_acc = history.history['val_acc']\n",
        "  loss = history.history['loss']\n",
        "  val_loss = history.history['val_loss']\n",
        "\n",
        "  # Write your own logging.\n",
        "  # log(history, start, precision, recall, fscore, acc_score, tn, fp, fn, tp)\n",
        "  min_val_loss = min(history.history['val_loss'])\n",
        "\n",
        "  now = datetime.now()\n",
        "  id = now.strftime('%Y%m%d%H%M%S')\n",
        "  elapsed_s = time.time() - start\n",
        "  elapsed = time.strftime('%H:%M:%S', time.gmtime(elapsed_s))\n",
        "\n",
        "  print(elapsed)\n",
        "\n",
        "  print('Accuracy: ', acc_score)\n",
        "  print('Precision: ', precision)\n",
        "  print('Recall: ', recall)\n",
        "  print('F-score: ', fscore)\n",
        "  '''\n",
        "  print('TN: ', tn)\n",
        "  print('FP: ', fp)\n",
        "  print('FN: ', fn)\n",
        "  print('TP: ', tp)\n",
        "  '''\n",
        "  return min_val_loss, precision, recall, fscore, acc, val_acc, loss, val_loss, id\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "oq8QorU4AeGY"
      },
      "outputs": [],
      "source": [
        "N = 1  # How many outer loops. Each contributes to the mean and standard deviation. 8\n",
        "M = 1  # Find the best (minimum) validation loss and fscore among M runs.4\n",
        "def main():\n",
        "  table_data = {}\n",
        "  for batch_size in BATCHES:\n",
        "            precisions = []\n",
        "            recalls = []\n",
        "            fscores = []\n",
        "            min_val_losses = []\n",
        "\n",
        "            # Evaluation framework.\n",
        "            for n in range(N):\n",
        "                best_precision = float('-inf')\n",
        "                best_recall = float('-inf')\n",
        "                best_fscore = float('-inf')\n",
        "                best_min_val_loss = float('inf')\n",
        "\n",
        "                # The learning algorithm.\n",
        "                # Choosing the best run based on training results among M runs.\n",
        "                for m in range(M):\n",
        "                    min_val_loss, precision, recall, fscore, acc, val_acc, loss, val_loss, id = run(batch_size)\n",
        "\n",
        "                    # Pick the best run based on the minimum validation loss.\n",
        "                    if min_val_loss < best_min_val_loss:\n",
        "                        best_min_val_loss = min_val_loss                \n",
        "                        best_fscore = fscore\n",
        "                        best_precision = precision\n",
        "                        best_recall = recall\n",
        "\n",
        "                    #plot(acc, val_acc, 'Accuracy', 'Validation accuracy', PLOT_SAVE_LOCATION, id, batch_size)\n",
        "                    #plot(loss, val_loss, 'Loss', 'Validation  loss', PLOT_SAVE_LOCATION, id, batch_size)\n",
        "\n",
        "                precisions.append(best_precision)\n",
        "                recalls.append(best_recall)\n",
        "                fscores.append(best_fscore)\n",
        "                min_val_losses.append(best_min_val_loss)\n",
        "\n",
        "            # Get results for LaTeX table.\n",
        "            p_mean = np.mean(precisions)\n",
        "            r_mean = np.mean(recalls)\n",
        "            f_mean = np.mean(fscores)\n",
        "            min_val_loss_mean = np.mean(min_val_losses)\n",
        "\n",
        "            p_std = np.std(precisions)\n",
        "            r_std = np.std(recalls)\n",
        "            f_std = np.std(fscores)\n",
        "            min_val_loss_std = np.std(min_val_losses)\n",
        "            '''\n",
        "            print(p_mean)\n",
        "            print(r_mean)\n",
        "            print(f_mean)\n",
        "            print(min_val_loss_mean)\n",
        "\n",
        "            print(p_std)\n",
        "            print(r_std)\n",
        "            print(f_std)\n",
        "            print(min_val_loss_std)\n",
        "            '''\n",
        "            table_data[batch_size] = {\n",
        "                'p_mean': p_mean,\n",
        "                'p_std': p_std,\n",
        "                'r_mean': r_mean,\n",
        "                'r_std': r_std,\n",
        "                'f_mean': f_mean,\n",
        "                'f_std': f_std\n",
        "            }\n",
        "\n",
        "    # Enable automatic LaTeX table creation of the results.\n",
        "    # create_latex_table(table_data, id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KnCTRbH5FGG6",
        "outputId": "22efd52e-a171-489d-e350-43a874f357cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " block1_conv (Conv2D)        (None, 80, 12, 10)        220       \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 40, 6, 10)         0         \n",
            "                                                                 \n",
            " block1_norm (BatchNormaliza  (None, 40, 6, 10)        40        \n",
            " tion)                                                           \n",
            "                                                                 \n",
            " block2_conv (Conv2D)        (None, 40, 6, 20)         1820      \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 20, 3, 20)         0         \n",
            "                                                                 \n",
            " block2_norm (BatchNormaliza  (None, 20, 3, 20)        80        \n",
            " tion)                                                           \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1200)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               307456    \n",
            "                                                                 \n",
            " dense_norm (BatchNormalizat  (None, 256)              1024      \n",
            " ion)                                                            \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 256)               0         \n",
            "                                                                 \n",
            " pred (Dense)                (None, 2)                 514       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 311,154\n",
            "Trainable params: 310,582\n",
            "Non-trainable params: 572\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "1487/1487 [==============================] - 118s 79ms/step - loss: 0.0983 - acc: 0.9660 - val_loss: 0.0245 - val_acc: 0.9909\n",
            "Epoch 2/50\n",
            "1487/1487 [==============================] - 126s 85ms/step - loss: 0.0368 - acc: 0.9877 - val_loss: 0.0224 - val_acc: 0.9925\n",
            "Epoch 3/50\n",
            "1487/1487 [==============================] - 127s 85ms/step - loss: 0.0311 - acc: 0.9900 - val_loss: 0.0169 - val_acc: 0.9939\n",
            "Epoch 4/50\n",
            "1487/1487 [==============================] - 131s 88ms/step - loss: 0.0281 - acc: 0.9908 - val_loss: 0.0201 - val_acc: 0.9927\n",
            "Epoch 5/50\n",
            "1487/1487 [==============================] - 125s 84ms/step - loss: 0.0281 - acc: 0.9910 - val_loss: 0.0221 - val_acc: 0.9914\n",
            "Epoch 6/50\n",
            "1487/1487 [==============================] - 119s 80ms/step - loss: 0.0266 - acc: 0.9914 - val_loss: 0.0325 - val_acc: 0.9898\n",
            "Epoch 7/50\n",
            "1487/1487 [==============================] - 124s 83ms/step - loss: 0.0237 - acc: 0.9921 - val_loss: 0.0175 - val_acc: 0.9940\n",
            "Epoch 8/50\n",
            "1487/1487 [==============================] - 121s 81ms/step - loss: 0.0218 - acc: 0.9929 - val_loss: 0.0268 - val_acc: 0.9909\n",
            "Epoch 9/50\n",
            "1487/1487 [==============================] - 126s 85ms/step - loss: 0.0205 - acc: 0.9934 - val_loss: 0.0198 - val_acc: 0.9931\n",
            "Epoch 10/50\n",
            "1487/1487 [==============================] - 129s 87ms/step - loss: 0.0212 - acc: 0.9930 - val_loss: 0.0207 - val_acc: 0.9920\n",
            "Epoch 11/50\n",
            "1487/1487 [==============================] - 146s 98ms/step - loss: 0.0193 - acc: 0.9932 - val_loss: 0.0177 - val_acc: 0.9939\n",
            "Epoch 12/50\n",
            "1487/1487 [==============================] - 151s 101ms/step - loss: 0.0189 - acc: 0.9937 - val_loss: 0.0193 - val_acc: 0.9936\n",
            "Epoch 13/50\n",
            "1487/1487 [==============================] - 145s 98ms/step - loss: 0.0173 - acc: 0.9939 - val_loss: 0.0251 - val_acc: 0.9929\n",
            "Epoch 14/50\n",
            "1487/1487 [==============================] - 149s 100ms/step - loss: 0.0173 - acc: 0.9943 - val_loss: 0.0240 - val_acc: 0.9930\n",
            "Epoch 15/50\n",
            "1487/1487 [==============================] - 149s 100ms/step - loss: 0.0168 - acc: 0.9943 - val_loss: 0.0204 - val_acc: 0.9932\n",
            "Epoch 16/50\n",
            "1487/1487 [==============================] - 148s 100ms/step - loss: 0.0161 - acc: 0.9945 - val_loss: 0.0228 - val_acc: 0.9925\n",
            "Epoch 17/50\n",
            "1487/1487 [==============================] - 154s 103ms/step - loss: 0.0152 - acc: 0.9947 - val_loss: 0.0226 - val_acc: 0.9923\n",
            "Epoch 18/50\n",
            "1487/1487 [==============================] - 150s 101ms/step - loss: 0.0153 - acc: 0.9949 - val_loss: 0.0254 - val_acc: 0.9926\n",
            "Epoch 19/50\n",
            "1487/1487 [==============================] - 133s 89ms/step - loss: 0.0153 - acc: 0.9946 - val_loss: 0.0281 - val_acc: 0.9915\n",
            "Epoch 20/50\n",
            "1487/1487 [==============================] - 120s 81ms/step - loss: 0.0143 - acc: 0.9948 - val_loss: 0.0307 - val_acc: 0.9924\n",
            "Epoch 21/50\n",
            "1487/1487 [==============================] - 127s 85ms/step - loss: 0.0144 - acc: 0.9950 - val_loss: 0.0232 - val_acc: 0.9923\n",
            "Epoch 22/50\n",
            "1487/1487 [==============================] - 149s 101ms/step - loss: 0.0141 - acc: 0.9951 - val_loss: 0.0196 - val_acc: 0.9935\n",
            "Epoch 23/50\n",
            "1487/1487 [==============================] - 147s 99ms/step - loss: 0.0134 - acc: 0.9953 - val_loss: 0.0202 - val_acc: 0.9933\n",
            "Epoch 24/50\n",
            "1487/1487 [==============================] - 148s 99ms/step - loss: 0.0132 - acc: 0.9955 - val_loss: 0.0245 - val_acc: 0.9923\n",
            "Epoch 25/50\n",
            "1487/1487 [==============================] - 148s 100ms/step - loss: 0.0129 - acc: 0.9954 - val_loss: 0.0211 - val_acc: 0.9923\n",
            "Epoch 26/50\n",
            "1487/1487 [==============================] - 148s 99ms/step - loss: 0.0128 - acc: 0.9955 - val_loss: 0.0253 - val_acc: 0.9925\n",
            "Epoch 27/50\n",
            "1487/1487 [==============================] - 144s 97ms/step - loss: 0.0121 - acc: 0.9959 - val_loss: 0.0284 - val_acc: 0.9930\n",
            "Epoch 28/50\n",
            "1487/1487 [==============================] - 145s 97ms/step - loss: 0.0121 - acc: 0.9957 - val_loss: 0.0271 - val_acc: 0.9930\n",
            "Epoch 29/50\n",
            "1487/1487 [==============================] - 144s 97ms/step - loss: 0.0119 - acc: 0.9958 - val_loss: 0.0244 - val_acc: 0.9934\n",
            "Epoch 30/50\n",
            "1487/1487 [==============================] - 146s 98ms/step - loss: 0.0117 - acc: 0.9960 - val_loss: 0.0209 - val_acc: 0.9939\n",
            "Epoch 31/50\n",
            "1487/1487 [==============================] - 149s 100ms/step - loss: 0.0110 - acc: 0.9964 - val_loss: 0.0324 - val_acc: 0.9918\n",
            "Epoch 32/50\n",
            "1487/1487 [==============================] - 157s 106ms/step - loss: 0.0117 - acc: 0.9959 - val_loss: 0.0316 - val_acc: 0.9922\n",
            "Epoch 33/50\n",
            "1487/1487 [==============================] - 156s 105ms/step - loss: 0.0107 - acc: 0.9961 - val_loss: 0.0239 - val_acc: 0.9928\n",
            "Epoch 34/50\n",
            "1487/1487 [==============================] - 151s 101ms/step - loss: 0.0104 - acc: 0.9964 - val_loss: 0.0314 - val_acc: 0.9930\n",
            "Epoch 35/50\n",
            "1487/1487 [==============================] - 149s 100ms/step - loss: 0.0104 - acc: 0.9964 - val_loss: 0.0235 - val_acc: 0.9934\n",
            "Epoch 36/50\n",
            "1487/1487 [==============================] - 145s 97ms/step - loss: 0.0105 - acc: 0.9964 - val_loss: 0.0324 - val_acc: 0.9919\n",
            "Epoch 37/50\n",
            "1487/1487 [==============================] - 130s 88ms/step - loss: 0.0096 - acc: 0.9968 - val_loss: 0.0429 - val_acc: 0.9913\n",
            "Epoch 38/50\n",
            "1487/1487 [==============================] - 112s 75ms/step - loss: 0.0095 - acc: 0.9968 - val_loss: 0.0270 - val_acc: 0.9926\n",
            "Epoch 39/50\n",
            "1487/1487 [==============================] - 126s 85ms/step - loss: 0.0103 - acc: 0.9966 - val_loss: 0.0304 - val_acc: 0.9935\n",
            "Epoch 40/50\n",
            "1487/1487 [==============================] - 117s 79ms/step - loss: 0.0093 - acc: 0.9968 - val_loss: 0.0263 - val_acc: 0.9929\n",
            "Epoch 41/50\n",
            "1487/1487 [==============================] - 106s 71ms/step - loss: 0.0088 - acc: 0.9966 - val_loss: 0.0333 - val_acc: 0.9928\n",
            "Epoch 42/50\n",
            "1487/1487 [==============================] - 104s 70ms/step - loss: 0.0092 - acc: 0.9968 - val_loss: 0.0378 - val_acc: 0.9920\n",
            "Epoch 43/50\n",
            "1487/1487 [==============================] - 102s 68ms/step - loss: 0.0089 - acc: 0.9970 - val_loss: 0.0309 - val_acc: 0.9926\n",
            "Epoch 44/50\n",
            "1487/1487 [==============================] - 109s 74ms/step - loss: 0.0094 - acc: 0.9967 - val_loss: 0.0331 - val_acc: 0.9927\n",
            "Epoch 45/50\n",
            "1487/1487 [==============================] - 110s 74ms/step - loss: 0.0086 - acc: 0.9972 - val_loss: 0.0260 - val_acc: 0.9925\n",
            "Epoch 46/50\n",
            "1487/1487 [==============================] - 113s 76ms/step - loss: 0.0091 - acc: 0.9968 - val_loss: 0.0302 - val_acc: 0.9926\n",
            "Epoch 47/50\n",
            "1487/1487 [==============================] - 112s 75ms/step - loss: 0.0086 - acc: 0.9971 - val_loss: 0.0327 - val_acc: 0.9926\n",
            "Epoch 48/50\n",
            "1487/1487 [==============================] - 126s 85ms/step - loss: 0.0080 - acc: 0.9970 - val_loss: 0.0351 - val_acc: 0.9923\n",
            "Epoch 49/50\n",
            "1487/1487 [==============================] - 136s 92ms/step - loss: 0.0082 - acc: 0.9970 - val_loss: 0.0271 - val_acc: 0.9924\n",
            "Epoch 50/50\n",
            "1487/1487 [==============================] - 140s 94ms/step - loss: 0.0084 - acc: 0.9971 - val_loss: 0.0328 - val_acc: 0.9921\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-06-10 23:31:12.060851: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,256]\n",
            "\t [[{{node inputs}}]]\n",
            "2023-06-10 23:31:12.272409: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,256]\n",
            "\t [[{{node inputs}}]]\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./model_sd/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./model_sd/assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "413/413 [==============================] - 5s 12ms/step\n",
            "01:52:29\n",
            "Accuracy:  0.9918262317414668\n",
            "Precision:  0.9820103594343281\n",
            "Recall:  0.8783250453637136\n",
            "F-score:  0.9235186673955686\n"
          ]
        }
      ],
      "source": [
        "main()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
